import os
import pandas as pd
import psycopg2
import numpy as np
import xgboost as xgb
import mlflow
from pycaret.regression import *
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import train_test_split

os.environ["MLFLOW_S3_ENDPOINT_URL"] = os.getenv("MLFLOW_S3_ENDPOINT_URL", "http://mlflow-artifact-store:9000")
os.environ["MLFLOW_TRACKING_URI"] = os.getenv("MLFLOW_TRACKING_URI", "http://mlflow-server:5000")
os.environ["AWS_ACCESS_KEY_ID"] = os.getenv("AWS_ACCESS_KEY_ID")
os.environ["AWS_SECRET_ACCESS_KEY"] = os.getenv("AWS_SECRET_ACCESS_KEY")

class Preprocessor:
    """ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self):
        self.X_features = ["ì¸µ", "ë²•ì •ë™ì½”ë“œ", "ê±´ì¶•ë…„ë„", "ê±´ë¬¼ë©´ì _ã¡"]
        self.y_target = "ë¬¼ê±´ê¸ˆì•¡_ë§Œì›"
        self.scaler = RobustScaler()

    def fetch_data_from_db(self):
        """DBì—ì„œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"""
        print("ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")

        query = "SELECT * FROM estate_details;"

        with psycopg2.connect(
                user=os.getenv("TRAIN_USER"),
                password=os.getenv("TRAIN_PASSWORD"),
                host=os.getenv("TRAIN_HOST"),
                database=os.getenv("TRAIN_DB"),
                port=5432
        ) as conn:
            with conn.cursor() as cursor:
                cursor.execute(query)
                records = cursor.fetchall()

                # âœ… DataFrame ë³€í™˜
                df = pd.DataFrame(records, columns=[desc[0] for desc in cursor.description])

        if df.empty:
            raise ValueError("ğŸš¨ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¶ˆëŸ¬ì˜¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")

        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ! {df.shape[0]}ê°œì˜ ë°ì´í„°")
        return df

    def preprocess_and_scale(self, df):
        """
        ë°ì´í„° ì „ì²˜ë¦¬ ë° ìŠ¤ì¼€ì¼ë§:
          - ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°
          - í•„ìš”í•œ ì»¬ëŸ¼ ì„ íƒ
          - ê²°ì¸¡ì¹˜ ì²˜ë¦¬
          - íƒ€ê²Ÿ ë³€ìˆ˜ ë¡œê·¸ ë³€í™˜ (np.log1p)
          - ë…ë¦½ ë³€ìˆ˜ì— RobustScaler ì ìš©
          - ìŠ¤ì¼€ì¼ë§ëœ ë…ë¦½ ë³€ìˆ˜ì™€ ë¡œê·¸ ë³€í™˜ëœ íƒ€ê²Ÿì„ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ ë°˜í™˜ (íƒ€ê²Ÿ ì»¬ëŸ¼ëª…: 'target')
        """
        print("ğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ë° ìŠ¤ì¼€ì¼ë§ ì¤‘...")
        # ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±° ë° í•„ìš”í•œ ì»¬ëŸ¼ ì„ íƒ
        df = df.drop(columns=["id", "estate_id"], errors="ignore")
        df = df[self.X_features + [self.y_target]]

        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        df.fillna(df.median(), inplace=True)

        # íƒ€ê²Ÿ ë³€ìˆ˜ ë¡œê·¸ ë³€í™˜ (np.log1p)
        df[self.y_target] = np.log1p(df[self.y_target])

        # ë…ë¦½ ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§ (RobustScaler)
        X_scaled = self.scaler.fit_transform(df[self.X_features])
        df_scaled = pd.DataFrame(X_scaled, columns=self.X_features)

        # ë¡œê·¸ ë³€í™˜ëœ íƒ€ê²Ÿ ë³€ìˆ˜ ì¶”ê°€ (ì»¬ëŸ¼ëª…: 'target')
        df_scaled["target"] = df[self.y_target].values
        print("âœ… ë°ì´í„° ì „ì²˜ë¦¬ ë° ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ!")
        return df_scaled


class Automation:
    """PyCaret AutoML í´ë˜ìŠ¤"""

    def __init__(self, preprocessor):
        self.preprocessor = preprocessor
        self.results_df = None

    def train_pycaret(self):
        """PyCaret AutoML ì‹¤í–‰"""
        df = self.preprocessor.fetch_data_from_db()
        # preprocess_and_scale() ë‚´ì—ì„œ ì „ì²˜ë¦¬ì™€ ìŠ¤ì¼€ì¼ë§ì„ ëª¨ë‘ ì²˜ë¦¬í•˜ê³  'target'ìœ¼ë¡œ ì»¬ëŸ¼ëª…ì„ ë³€ê²½
        df_scaled = self.preprocessor.preprocess_and_scale(df)

        mlflow.set_experiment("pycaret_automl")
        print("ğŸ“Š PyCaret AutoML ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")

        with mlflow.start_run():
            setup(data=df_scaled, target="target", log_experiment=True, experiment_name="pycaret_automl", verbose=False)
            best_model = compare_models()
            self.results_df = pull()

            for _, row in self.results_df.iterrows():
                mlflow.log_param("model_name", row["Model"])
                mlflow.log_metric("mae", row["MAE"])
                mlflow.log_metric("r2", row["R2"])
                mlflow.log_metric("rmse", row["RMSE"])

    def get_results(self):
        """PyCaret ê²°ê³¼ ë°˜í™˜"""
        if self.results_df is None:
            raise ValueError("ğŸš¨ ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        return self.results_df



class EstatePredict:
    """XGBoost ëª¨ë¸ (Optuna ìƒëµí•œ ì˜ˆì‹œ)"""

    def __init__(self, preprocessor):
        self.preprocessor = preprocessor
        self.best_params = {
            "n_estimators": 100,
            "max_depth": 6,
            "learning_rate": 0.1,
            "subsample": 1.0,
            "colsample_bytree": 1.0
        }
        self.model = xgb.XGBRegressor(**self.best_params, random_state=42)

    def fit(self):
        """XGBoost ëª¨ë¸ í•™ìŠµ ë° MLflow ë¡œê¹…"""
        print("ğŸ“Š XGBoost ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        print("í›ˆë ¨ì¤‘...")  # ì§„í–‰ ë©”ì‹œì§€ ì¶œë ¥

        # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ + ìŠ¤ì¼€ì¼ë§ (ë‹¨ì¼ DataFrame ë°˜í™˜)
        df = self.preprocessor.fetch_data_from_db()
        df_scaled = self.preprocessor.preprocess_and_scale(df)

        # train/test split (ì˜ˆ: 80:20 ë¹„ìœ¨)
        X = df_scaled[self.preprocessor.X_features]
        y = df_scaled["target"]
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # MLflow ì‹¤í—˜ ì„¤ì •
        mlflow.set_experiment("xgboost_optuna")
        with mlflow.start_run():
            mlflow.log_params(self.best_params)

            # ëª¨ë¸ í•™ìŠµ
            self.model.fit(
                X_train, y_train,
                eval_set=[(X_test, y_test)],
                verbose=True
            )

            # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
            y_pred = self.model.predict(X_test)
            mae = np.mean(np.abs(y_test - y_pred))
            rmse = np.sqrt(np.mean((y_test - y_pred) ** 2))
            r2 = 1 - (np.sum((y_test - y_pred) ** 2) / np.sum((y_test - np.mean(y_test)) ** 2))

            mlflow.log_metric("mae", mae)
            mlflow.log_metric("rmse", rmse)
            mlflow.log_metric("r2", r2)
            mlflow.xgboost.log_model(self.model, artifact_path="xgboost_model")

            print(f"âœ… MLflowì— ëª¨ë¸ ì €ì¥ ì™„ë£Œ! (MAE: {mae:.4f}, RMSE: {rmse:.4f}, RÂ²: {r2:.4f})")

class MetricSave:
    """ëª¨ë¸ í‰ê°€ ê²°ê³¼ DB ì €ì¥"""

    def __init__(self):
        self.conn = psycopg2.connect(
            user=os.getenv("TRAIN_USER"),
            password=os.getenv("TRAIN_PASSWORD"),
            host=os.getenv("TRAIN_HOST"),
            database=os.getenv("TRAIN_DB")
        )
        self.cursor = self.conn.cursor()

    def save_results(self, results_df):
        """PyCaret í‰ê°€ ê²°ê³¼ DB ì €ì¥"""
        for _, row in results_df.iterrows():
            self.cursor.execute(
                "INSERT INTO model_results (model_name, mae, r2, rmse) VALUES (%s, %s, %s, %s);",
                (row["Model"], row["MAE"], row["R2"], row["RMSE"])
            )
        self.conn.commit()

    def close_connection(self):
        """DB ì—°ê²° ì¢…ë£Œ"""
        self.cursor.close()
        self.conn.close()
